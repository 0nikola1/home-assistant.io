<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: How-To | Home Assistant]]></title>
  <link href="https://home-assistant.io/blog/categories/how-to/atom.xml" rel="self"/>
  <link href="https://home-assistant.io/"/>
  <updated>2016-07-22T18:25:13+00:00</updated>
  <id>https://home-assistant.io/</id>
  <author>
    <name><![CDATA[Paulus Schoutsen]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Visualize your IoT data]]></title>
    <link href="https://home-assistant.io/blog/2016/07/19/visualizing-your-iot-data/"/>
    <updated>2016-07-19T16:00:00+00:00</updated>
    <id>https://home-assistant.io/blog/2016/07/19/visualizing-your-iot-data</id>
    <content type="html"><![CDATA[<p><img src="https://home-assistant.io/images/blog/2016-07-reporting/mpl-sensor.png" style="clear: right; border:none; box-shadow: none; float: right; margin-bottom: 12px;" width="200" /></p>

<p>The <a href="/components/history/">history component</a> is tracking everything that is going on within Home Assistant. This means that you have access to all stored information about your home. Our history is not a full-fledged graphical processing and visualization component as you may know from systems and network monitoring tools. The current limitation is that you only can select a day for a visual output of your information and not a period. Also, there is no possibility to drill down on a specific entity.</p>

<p>This blog post will show you ways to export data for reporting, visualization, or further analysis of automation rules.</p>

<!--more-->

<p>In this blog post I use the temperature of the <a href="https://en.wikipedia.org/wiki/Aare">Aare</a> river close to where I live as a show case. The temperatures were recorded with the <a href="/components/sensor.swiss_hydrological_data/">Swiss Hydrological Data sensor</a> and the name of the sensor is <code>sensor.aare</code>.</p>

<p>The database is stored at <code>&lt;path to config dir&gt;/.homeassistant/home-assistant_v2.db</code> as <a href="https://www.sqlite.org/">SQLite database</a>. In all examples we are going to use the path: <code>/home/ha/.homeassistant/home-assistant_v2.db</code></p>

<p>If you are just curious what’s stored in your database then you can use the <code>sqlite3</code> command-line tool or a graphical one like <a href="http://sqlitebrowser.org/">DB Browser for SQLite</a>.</p>

<p>The table that is holding the states is called <code>states</code>. The <code>events</code> tables is responsible for storing the events which occurred. So, we will first check how many entries there are in the <code>states</code> table. <code>sqlite3</code> needs to know where the databases is located. To work with your database make sure that Home Assistant is not running or create a copy of the existing database. It’s recommended to work with a copy.</p>

<div class="highlighter-coderay"><div class="CodeRay">
  <div class="code"><pre>$ sqlite3 /home/ha/.homeassistant/home-assistant_v2.db 
SQLite version 3.11.0 2016-02-15 17:29:24
sqlite&gt; SELECT count(*) FROM states;
24659
</pre></div>
</div>
</div>

<p>Let’s have a look at a sample <a href="https://en.wikipedia.org/wiki/SQL">SQL</a> query. This query will show all states in a period for the sensor <code>sensor.aare</code>.</p>

<div class="highlighter-coderay"><div class="CodeRay">
  <div class="code"><pre><span class="class">SELECT</span> state, last_changed <span class="keyword">FROM</span> states
  <span class="keyword">WHERE</span>
    entity_id = <span class="string"><span class="delimiter">'</span><span class="content">sensor.aare</span><span class="delimiter">'</span></span>
  <span class="keyword">AND</span>
     last_changed <span class="keyword">BETWEEN</span>
    <span class="string"><span class="delimiter">'</span><span class="content">2016-07-05 00:00:00.000000</span><span class="delimiter">'</span></span> <span class="keyword">AND</span> <span class="string"><span class="delimiter">'</span><span class="content">2016-07-07 00:00:00.000000</span><span class="delimiter">'</span></span>;
</pre></div>
</div>
</div>

<p>The SQL statement can be formed that it fits exactly what you need. This means that you can process the data in any way you want for further use. Often it makes sense to eliminate certain entries like <code>Unknown</code> or peaks.</p>

<p>If the above query is executed in DB Browser for SQLite you would be able to save the sensor’s graph as png.</p>

<p class="img">
  <img src="https://home-assistant.io/images/blog/2016-07-reporting/db-browser.png" />
  Visualization with DB Browser for SQLite
</p>

<p>You may ask: Why not do this with LibreOffice Calc or another spreadsheet application? As most spreadsheet applications are not able to work directly with SQLite database we are going to export the data from the database to <a href="https://en.wikipedia.org/wiki/Comma-separated_values">CSV</a>.</p>

<div class="highlighter-coderay"><div class="CodeRay">
  <div class="code"><pre>$ sqlite3 -header -csv /home/ha/.homeassistant/home-assistant_v2.db &quot;SELECT last_changed, state FROM states WHERE entity_id = 'sensor.aare' AND last_changed BETWEEN '2016-07-05 00:00:00.000000' AND '2016-07-07 00:00:00.000000';&quot; &gt; sensor.csv
</pre></div>
</div>
</div>

<p>The ordering for the <code>SELECT</code> was changed to get the time stamps first and then the state. Now we can import the CSV file into the application of your choice, here it’s LibreOffice Calc.</p>

<p class="img">
  <img src="https://home-assistant.io/images/blog/2016-07-reporting/libreoffice-import.png" />
  Import of the CSV file 
</p>

<p>After the import a graph can be created over the existing data.</p>

<p class="img">
  <img src="https://home-assistant.io/images/blog/2016-07-reporting/libreoffice-graph.png" />
  Graph in LibreOffice
</p>

<p>You can also use <a href="http://matplotlib.org/">matplotlib</a> to generate graphs as an alternative to a spreadsheet application. This is a powerful Python 2D plotting library. With the built-in support for SQLite in Python it will only take a couple lines of code to visualize your data.</p>

<div class="highlighter-coderay"><div class="CodeRay">
  <div class="code"><pre><span class="keyword">import</span> <span class="include">sqlite3</span>
<span class="keyword">from</span> <span class="include">matplotlib</span> <span class="keyword">import</span> <span class="include">dates</span>
<span class="keyword">import</span> <span class="include">matplotlib.pyplot</span> <span class="keyword">as</span> plt

<span class="keyword">import</span> <span class="include">homeassistant.util.dt</span> <span class="keyword">as</span> dt

values = []
timestamps = []

conn = sqlite3.connect(<span class="string"><span class="delimiter">'</span><span class="content">/home/ha/.homeassistant/home-assistant_v2.db</span><span class="delimiter">'</span></span>)
data = conn.execute(<span class="string"><span class="delimiter">&quot;</span><span class="content">SELECT state, last_changed FROM states WHERE </span><span class="delimiter">&quot;</span></span>
                    <span class="string"><span class="delimiter">&quot;</span><span class="content">entity_id = 'sensor.aare' AND last_changed BETWEEN </span><span class="delimiter">&quot;</span></span>
                    <span class="string"><span class="delimiter">&quot;</span><span class="content">'2016-07-05 00:00:00.000000' AND </span><span class="delimiter">&quot;</span></span>
                    <span class="string"><span class="delimiter">&quot;</span><span class="content">'2016-07-07 00:00:00.000000'</span><span class="delimiter">&quot;</span></span>)

<span class="keyword">for</span> x <span class="keyword">in</span> data:
    timestamps.append(dates.date2num(dt.parse_datetime(x[<span class="integer">1</span>])))
    values.append(<span class="predefined">float</span>(x[<span class="integer">0</span>]))

plt.plot_date(x=timestamps, y=values, fmt=<span class="string"><span class="delimiter">&quot;</span><span class="content">r-</span><span class="delimiter">&quot;</span></span>)
plt.ylabel(<span class="string"><span class="delimiter">'</span><span class="content">Temperature</span><span class="delimiter">'</span></span>)
plt.xlabel(<span class="string"><span class="delimiter">'</span><span class="content">Time line</span><span class="delimiter">'</span></span>)

plt.savefig(<span class="string"><span class="delimiter">'</span><span class="content">sensor.png</span><span class="delimiter">'</span></span>)
</pre></div>
</div>
</div>

<p>Creating a connection to the database and executing a query is similar to the ways already seen. The return values from the query are splitted into two lists. The time stamps must be converted in an value which is accepted by matplotlib and then the graph is generated and saved as image.</p>

<p class="img">
  <img src="https://home-assistant.io/images/blog/2016-07-reporting/mpl-sensor.png" />
  Sensor graph generated by matplotlib
</p>

<p>Most of the graphs are pretty ugly. So, further beautification will be needed. If you have created a nice report including some amazing graphs then the Home Assistant community would be grateful for sharing them in our <a href="https://community.home-assistant.io/">forum</a>.</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[PocketCHIP running Home Assistant]]></title>
    <link href="https://home-assistant.io/blog/2016/07/06/pocketchip-running-home-assistant/"/>
    <updated>2016-07-06T05:00:00+00:00</updated>
    <id>https://home-assistant.io/blog/2016/07/06/pocketchip-running-home-assistant</id>
    <content type="html"><![CDATA[<p><img src="https://home-assistant.io/images/blog/2016-07-pocketchip/pocketchip-logo.png" style="clear: right; border:none; box-shadow: none; float: right; margin-bottom: 12px;" width="200" /><br />
Over a year ago I participated in the <a href="https://www.kickstarter.com/projects/1598272670/chip-the-worlds-first-9-computer/description">kickstarter campaign</a> for “CHIP - The World’s First Nine Dollar Computer” by <a href="https://www.nextthing.co/">Next Thing Co.</a>. I went for the PocketCHIP because of the idea. Display, built-in storage (thus no need for SD cards), battery-powered, and a keyboard are pretty nice features. Last week a package arrives…</p>

<!--more-->

<p>Thanks to <a href="https://www.nextthing.co/">Next Thing Co.</a> and their CHIP which is actually 9 USD the space requirement for a single board computer has decreased. No Ethernet and HDMI output helped with that. But I guess that the next development cycle will allow us to put those boards in a matchbox including wired networking and a SATA interface.</p>

<p class="img">
  <img src="https://home-assistant.io/images/blog/2016-07-pocketchip/size.png" />
  Size comparison of a Cubieboard, OrangePi One, and CHIP.
</p>

<p>If you start using a PocketCHIP you will definitely look like a Blackberry or a GameBoy user. Typing is done with your thumbs :-)</p>

<p>First a couple of tweaks like setting up <code>sudo</code>, upgrading the existing installation, change passwords, enabling ssh, and removal of the annoying stuff then installation of Home Assistant. There is not much to tell…it’s straight-forward. For the sake of completeness below the notes about what I did.</p>

<p>A Debian installation is available by default. This means that some dependencies for Home Assistant are missing. I haven’t checked if a new build for the PocketCHIP would include them. So, after a <code>$ sudo apt-get update</code> installing those dependencies take a minute or two.</p>

<div class="highlighter-coderay"><div class="CodeRay">
  <div class="code"><pre>$ sudo apt-get install python3-dev python3-pip python3-venv
</pre></div>
</div>
</div>

<p>As usual I run Python applications in a <a href="https://docs.python.org/3/library/venv.html">venv</a>.</p>

<div class="highlighter-coderay"><div class="CodeRay">
  <div class="code"><pre>$ pvenv ha
</pre></div>
</div>
</div>

<p>Let’s activate the created environment.</p>

<div class="highlighter-coderay"><div class="CodeRay">
  <div class="code"><pre>$ cd ha
$ source bin/activate
</pre></div>
</div>
</div>

<p>If you haven’t seen the next two commands already then you should visit our <a href="https://home-assistant.io/">frontsite</a>.</p>

<div class="highlighter-coderay"><div class="CodeRay">
  <div class="code"><pre>$ pip3 install homeassistant
$ hass --open-ui
</pre></div>
</div>
</div>

<p>With <code>surf</code> the browsing experience on the low-resolution display is not that great. Most smartphones, even very cheap ones, have touchscreens with higher resolutions. Nevermind, <a href="https://twitter.com/fabaff/status/748852317047418880"><code>midori</code></a> is not better.</p>

<p class="img">
  <img src="https://home-assistant.io/images/blog/2016-07-pocketchip/pocketchip.png" />
  PocketCHIP with Home Assistant frontend
</p>

<p>Well, with PocketCHIP and Home Assistant you could run your home automation on a 49 USD device with a touchscreen, an integrated USP, and a keyboard. With the GPIO available on top of the display you could even connect your PocketCHIP directly to sensors and actuators.</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Using USB webcams with Home Assistant]]></title>
    <link href="https://home-assistant.io/blog/2016/06/23/usb-webcams-and-home-assistant/"/>
    <updated>2016-06-23T06:00:00+00:00</updated>
    <id>https://home-assistant.io/blog/2016/06/23/usb-webcams-and-home-assistant</id>
    <content type="html"><![CDATA[<p><img src="https://home-assistant.io/images/blog/2016-06-cranberry/motion.png" style="clear: right; border:none; box-shadow: none; float: right; margin-bottom: 12px;" width="200" /><br />
In the past month I was thinking about ways to integrate USB webcams into Home Assistant again. The main reason was that this would give those devices a second life and enable one to benefit from low-cost video surveillance. There are a couple of options available like <a href="http://www.pygame.org/hifi.html">pygame</a> or <a href="http://www.simplecv.org/">SimpleCV</a> but I never finished something. With the <a href="https://home-assistant.io/components/camera.local_file/">Local File camera platform</a> by <a href="https://github.com/Landrash">Landrash</a> and <a href="http://lavrsen.dk/foswiki/bin/view/Motion/WebHome">motion</a> you could integrate a local USB webcam with a few very easy steps.</p>

<p>In this blog post I am using a Fedora 24 (will most likely work on other distributions too) installation with Home Assistant 0.22.1 on a Foxconn nT-330i with an old <a href="http://support.logitech.com/en_us/product/quickcam-sphere-af">Logitech QuickCam Orbit AF</a> and a <a href="http://support.logitech.com/en_us/product/hd-webcam-c270">Logitech HD Webcam C270</a>. As a start only the Quickcam is used. No multi-camera setup for now.</p>

<!--more-->

<p>Check first if the your operating system lists your cameras.</p>

<div class="highlighter-coderay"><div class="CodeRay">
  <div class="code"><pre>$ lsusb
[...]
Bus 002 Device 016: ID 046d:08cc Logitech, Inc. Mic (PTZ)
[...]
</pre></div>
</div>
</div>

<p>The camera we are going to use is available at <code>/dev/video1</code>. The C270 is the one on <code>/dev/video0</code>.</p>

<div class="highlighter-coderay"><div class="CodeRay">
  <div class="code"><pre>$ ls -al /dev/video*
crw-rw----+ 1 root video 81, 0 Jun 23 08:05 /dev/video0
crw-rw----+ 1 root video 81, 1 Jun 23 08:36 /dev/video1
</pre></div>
</div>
</div>

<p>We need an additional software part to handle the cameras. <a href="http://lavrsen.dk/foswiki/bin/view/Motion/WebHome">motion</a> is capable of monitoring the video signal from USB and network cameras, do motion detection, and other nifty stuff like saving images, add text, or basic image manipulations. Make sure that you have the <a href="http://rpmfusion.org/">RPM Fusion respository</a> enabled.</p>

<div class="highlighter-coderay"><div class="CodeRay">
  <div class="code"><pre>$ sudo dnf -y install motion
</pre></div>
</div>
</div>

<p>For our setup we need to modify the file <code>/etc/motion/motion.conf</code>. For now the most important parameters are <code>videodevice</code>, <code>snapshot_interval</code>, and <code>target_dir</code>. The other settings can be left to their defaults. We are going to use the device <code>/dev/video1</code>, use a 30 seconds interval, and set the path to <code>/tmp</code>.</p>

<div class="highlighter-coderay"><div class="CodeRay">
  <div class="code"><pre>[...]
###########################################################
# Capture device options
############################################################

# Videodevice to be used for capturing  (default /dev/video0)
# for FreeBSD default is /dev/bktr0
videodevice /dev/video1

[..]
############################################################
# Snapshots (Traditional Periodic Webcam File Output)
############################################################

# Make automated snapshot every N seconds (default: 0 = disabled)
snapshot_interval 30

[...]
############################################################
# Target Directories and filenames For Images And Films
# For the options snapshot_, picture_, movie_ and timelapse_filename
# you can use conversion specifiers
# %Y = year, %m = month, %d = date,
# %H = hour, %M = minute, %S = second,
# %v = event, %q = frame number, %t = thread (camera) number,
# %D = changed pixels, %N = noise level,
# %i and %J = width and height of motion area,
# %K and %L = X and Y coordinates of motion center
# %C = value defined by text_event
# Quotation marks round string are allowed.
############################################################

# Target base directory for pictures and films
# Recommended to use absolute path. (Default: current working directory)
target_dir /tmp

[...]
</pre></div>
</div>
</div>

<p>It’s suggested that you adjust at least <code>width</code> and <code>height</code> to get a bigger image from your camera. If you are done, fire up <code>motion</code>.</p>

<div class="highlighter-coderay"><div class="CodeRay">
  <div class="code"><pre>$ sudo motion
[0] [NTC] [ALL] conf_load: Processing thread 0 - config file /etc/motion/motion.conf
[0] [ALR] [ALL] conf_cmdparse: Unknown config option &quot;sdl_threadnr&quot;
[0] [NTC] [ALL] motion_startup: Motion 3.3.0 Started
[0] [NTC] [ALL] motion_startup: Logging to file (/var/log/motion.log)
</pre></div>
</div>
</div>

<p>Your <code>target_dir</code> will start filling up with images from your camera. <code>motion</code> will create a symlink called <code>lastsnap.jpg</code> which always point to the latest snapshot. We will setup the <a href="https://home-assistant.io/components/camera.local_file/">Local File camera platform</a> to use this file.</p>

<div class="highlighter-coderay"><div class="CodeRay">
  <div class="code"><pre><span class="key">camera</span>:
  - <span class="string"><span class="content">platform: local_file</span></span>
    <span class="key">name</span>: <span class="string"><span class="content">Cranberry cam</span></span>
    <span class="key">file_path</span>: <span class="string"><span class="content">/tmp/lastsnap.jpg</span></span>
</pre></div>
</div>
</div>

<p class="img">
  <img src="https://home-assistant.io/images/blog/2016-06-cranberry/cam.png" />
  The “Cranberry cam” in action
</p>

<p>The machine with the attached USB camera will become a webcam server as well because <code>motion</code>’s built-in HTTP server is enabled by default. This means that you could connect your USB webcams to a different machine in your network, run <code>motion</code> there, adjust your firewall rules, and use Home Assistant to display the videos. Just check http://[IP of your webcam host]:8081/ to see the stream. This required more powerful hardware than using snapshots, of course.</p>

<p>In a scenario like this needs a <a href="https://home-assistant.io/components/camera.mjpeg/">Generic MJPEG IP Camera </a> in your <code>configuration.yaml</code> file.</p>

<div class="highlighter-coderay"><div class="CodeRay">
  <div class="code"><pre><span class="key">camera</span>:
  - <span class="string"><span class="content">platform: mjpeg</span></span>
    <span class="key">mjpeg_url</span>: <span class="string"><span class="content">http://[IP of your webcam host]:8081</span></span>
    <span class="key">name</span>: <span class="string"><span class="content">Cranberry Live cam</span></span>
</pre></div>
</div>
</div>

<p><a href="http://lavrsen.dk/foswiki/bin/view/Motion/WebHome">motion</a> is a powerful tool and this blog post only showed two very simple use cases. Take a look at the <a href="http://www.lavrsen.dk/foswiki/bin/view/Motion/MotionGuide">documentation</a> of <code>motion</code> to unleash its potential.</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Static website]]></title>
    <link href="https://home-assistant.io/blog/2016/04/07/static-website/"/>
    <updated>2016-04-07T06:28:00+00:00</updated>
    <id>https://home-assistant.io/blog/2016/04/07/static-website</id>
    <content type="html"><![CDATA[<p>The frontend of Home Assistant is served with the help of a local web server. If you have <a href="/getting-started/devices/#customizing-devices-and-services">customized</a> your installation you already use this functionality. The content of your folder <code>www</code> in your Home Assistant configuration directory (<code>.homeassistant</code>) is available under <code>/local</code> (eg. <a href="https://localhost:8123/local">https://localhost:8123/local</a>).</p>

<p>But there is more you can do! You can not only host images for customization there but HTML files or even web applications including CSS and Javascript.</p>

<p class="img">
<img src="https://home-assistant.io/images/blog/2016-04-display/ha-display.png" />
</p>

<!--more-->

<p>In the past the buzz word “Smart mirror” was used a couple of times in our <a href="https://gitter.im/balloob/home-assistant">chatroom</a> and even made it into the <a href="https://github.com/home-assistant/home-assistant/issues/1392">issue tracker</a>. The existing solutions (<a href="http://docs.smart-mirror.io/">Smart mirror</a>, <a href="http://michaelteeuw.nl/tagged/magicmirror">MagicMirror</a>, and <a href="https://github.com/HannahMitt/HomeMirror">HomeMirror</a>) seems to be overkill if you already have Home Assistant running somewhere in your house or apartment. Why not simple display a web page served by Home Assistant on the tablet? No app and no Raspberry Pi running in the background.</p>

<p>There are plenty of ways to achieve this…<a href="/developers/rest_api/">RESTful API</a>, <a href="/developers/python_api/">Python API</a>, or one of the <a href="/components/#history">history components</a>. If it is to be a web page I’m using the <a href="/components/mqtt_eventstream/">MQTT Eventstream component</a> and <a href="http://git.eclipse.org/c/paho/org.eclipse.paho.mqtt.javascript.git/tree/src">mqttws31.js</a>.</p>

<p>The <a href="https://pypi.python.org/pypi/hbmqtt">HBMQTT</a> broker provides websockets support for MQTT and mqttws31.js included in web page gives you access to the MQTT messages. It’s a matter of minutes. OK, it took a little longer because I’m not a Javascript guy to create the software part that will show details about your environment. The source is available at <a href="https://github.com/fabaff/home-assistant-display">https://github.com/fabaff/home-assistant-display</a> and the screenshot above shows the result. I guess that every person who is familiar with Javascript would be able to reduce the amount of code and to make it more flexible. Well, it’s a only prototype and showcase to include an image in this blog post.</p>

<p>I hope that this little article could give you an idea of extending Home Assistant in an unconventional way.</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Multi-room audio with Snapcast, Mopidy, and Home Assistant]]></title>
    <link href="https://home-assistant.io/blog/2016/02/18/multi-room-audio-with-snapcast/"/>
    <updated>2016-02-18T05:10:56+00:00</updated>
    <id>https://home-assistant.io/blog/2016/02/18/multi-room-audio-with-snapcast</id>
    <content type="html"><![CDATA[<p>Would you like to listen to music in every room in your home, controlled from one source? Then multi-room audio is for you.</p>

<p>Multi-room audio can be achieved by having a computer attached to speakers in every room. On each computer, services run to play and/or control the audio. With this DIY approach, the kind of computer and speakers is very much up to you. It could be your desktop computer with attached powered speakers, your HTPC hooked up to your TV and receiver, a Raspberry Pi with Amp or DAC, or even an Android device.</p>

<p>You’ll need two key software packages, besides Home Assistant. The first is <a href="https://www.mopidy.com/">Mopidy</a>, a music server that can play local files, or connect to streaming music services like Spotify. The second is <a href="https://github.com/badaix/snapcast/">Snapcast</a>, which enables synchronized audio streaming across your network. Both can be integrated into Home Assistant. Each room audio device will run an instance of the Snapcast client, and optionally a Mopidy instance. Your server will run a special instance of Mopidy and the Snapcast server.</p>

<p>Finally, you also need a player to control Mopidy. Any MPD-compatible player will work, and there are several <a href="https://docs.mopidy.com/en/latest/ext/web/#ext-web">Mopidy-only web-based options</a> available. On Android, <a href="https://play.google.com/store/apps/details?id=se.anil.remotedy">Remotedy</a> is particularly nice since you can access multiple Mopidy instances in one place.</p>

<p>Home Assistant will provide device status, and volume control for each room. If you want to play music in all your rooms (on all your clients), access the server instance of Mopidy. If you want to play music only in a specific room, access that specific Mopidy instance. If you’re using a web UI for Mopidy, you can add links to each instance in Home Assistant with the <a href="/components/weblink/">weblink</a> component.</p>

<p class="img">
  <img src="https://home-assistant.io/images/blog/2016-02-snapcast/diagram.png" />
</p>

<!--more-->

<h2>Staging</h2>

<ul>
  <li><a href="https://www.mopidy.com/">Install</a> Mopidy (2.0.0 or greater)</li>
  <li><a href="https://github.com/badaix/snapcast/releases/">Download</a> and <a href="https://github.com/badaix/snapcast/tree/v0.5.0-beta-1#installation">Install</a> Snapcast (0.5.0 or greater)</li>
</ul>

<h2>Configure Mopidy</h2>

<p>Mopidy can be run with multiple configuration files, each extending the previous file. This is helpful when we’re running multiple instances with varying functionality.</p>

<h3>core.conf</h3>
<p>The core configuration is shared between all instances:</p>

<div class="highlighter-coderay"><div class="CodeRay">
  <div class="code"><pre>[mpd]
hostname = ::

[http]
hostname = ::

[audio]
output = alsasink

[spotify]
username = &lt;redacted&gt;
password = &lt;redacted&gt;
</pre></div>
</div>
</div>

<h3>local.conf</h3>
<p>Add the local configuration on computers that have local media files:</p>

<div class="highlighter-coderay"><div class="CodeRay">
  <div class="code"><pre>[local]
media_dir = &lt;your/music/here&gt;
</pre></div>
</div>
</div>

<h3>snapcast.conf</h3>
<p>Finally, the Mopidy instance that connects with Snapcast needs special configuration. Run on a different port to avoid conflicts if you have a second Mopidy instance running on your computer. The audio output is sent to a named pipe - Snapcast will read from there. Note that you may have to adjust the audio output attribute depending on your system and audio sources.</p>

<div class="highlighter-coderay"><div class="CodeRay">
  <div class="code"><pre>[mpd]
hostname = ::
port = 6601

[http]
hostname = ::
port = 6681

[audio]
output = audioresample ! audio/x-raw,rate=48000,channels=2,format=S16LE ! audioconvert ! wavenc ! filesink location=/tmp/snapfifo
</pre></div>
</div>
</div>

<h2>Run Mopidy</h2>

<p>To run a room-specific instance:</p>

<div class="highlighter-coderay"><div class="CodeRay">
  <div class="code"><pre>$ mopidy --config $CONF_DIR/core.conf
</pre></div>
</div>
</div>

<p>To run a room-specific instance with local media:</p>

<div class="highlighter-coderay"><div class="CodeRay">
  <div class="code"><pre>$ mopidy --config $CONF_DIR/core.conf:$CONF_DIR/local.conf
</pre></div>
</div>
</div>

<p>To run the special Snapcast-connected instance (with local media):</p>

<div class="highlighter-coderay"><div class="CodeRay">
  <div class="code"><pre>$ mopidy --config $CONF_DIR/core.conf:$CONF_DIR/local.conf:$CONF_DIR/snapcast.conf
</pre></div>
</div>
</div>

<h2>Run Snapcast</h2>

<p>Start the <code>snapserver</code> on the same server running Mopidy with the snapcast configuration.</p>

<div class="highlighter-coderay"><div class="CodeRay">
  <div class="code"><pre>$ snapserver   # or use systemd
</pre></div>
</div>
</div>

<p>Start the <code>snapclient</code> on computers that will be playing audio.</p>

<div class="highlighter-coderay"><div class="CodeRay">
  <div class="code"><pre>$ snapclient   # or use systemd, add -h &lt;server host&gt; if necessary
</pre></div>
</div>
</div>

<h2>Configure Snapcast</h2>

<p>There are a number of snapcast configuration options, but the one relevant to Home Assistant is the client names. You can set them in the snapserver configuration file, by default located at <code>~/.config/Snapcast/settings.json</code>. Only edit this file while the <code>snapserver</code> is not running. Modify the <code>name</code> JSON value to your liking - this is how the client will be named in Home Assistant.</p>

<h2>Configure Home Assistant</h2>

<p>Use the <a href="/components/media_player.mpd/">mpd</a> and <a href="/components/media_player.snapcast/">snapcast</a> components. Optionally, use <a href="/components/weblink/">weblink</a> to provide easy access to a Mopidy web UI.</p>

<div class="highlighter-coderay"><div class="CodeRay">
  <div class="code"><pre><span class="key">media_player</span>:
- <span class="string"><span class="content">platform: snapcast</span></span>
  <span class="key">host</span>: <span class="string"><span class="content">xxxxx</span></span>
- <span class="string"><span class="content">platform: mpd</span></span>
  <span class="key">server</span>: <span class="string"><span class="content">xxxx</span></span>
  <span class="key">location</span>: <span class="string"><span class="content">Multi-Room Controller</span></span>
- <span class="string"><span class="content">platform: mpd</span></span>
  <span class="key">server</span>: <span class="string"><span class="content">xxx</span></span>
  <span class="key">location</span>: <span class="string"><span class="content">Room 1</span></span>

<span class="key">weblink</span>:
  <span class="key">entities</span>:
  - <span class="string"><span class="content">name: Multi-Room Player</span></span>
    <span class="key">url</span>: <span class="string"><span class="content">xxxx</span></span>
</pre></div>
</div>
</div>

]]></content>
  </entry>
  
</feed>
